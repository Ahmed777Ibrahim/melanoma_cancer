{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056cf425-3e15-41a9-ae46-1a4879de6703",
   "metadata": {},
   "source": [
    "## loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3f3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870f21a-f8d3-4e3f-9175-2382051a260f",
   "metadata": {},
   "source": [
    "***in this code we define detData function to import all images into arraies for X_train,y_train,X_test,y_test ,note for img in sorted(os.listdir(path+data_name+'/'+typ),key=natural_sort_key) to import images in the same sort as folders which sort in name ,the benefit of that will be later when exporting images back to files that to be sure it exported right ,the way function natural_sort_key work is simply from the names of original data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e78829-b873-4ee3-a22f-af9185d2870a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "sorted_list = sorted([\"k_1\", \"k_2\", \"k_10\"], key=natural_sort_key)\n",
    "print(sorted_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3213b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getData(path):\n",
    "    X_train,y_train,X_test,y_test,=[],[],[],[]\n",
    "    for data_name in os.listdir(path):\n",
    "            for typ in os.listdir(path+data_name):\n",
    "                for img in sorted(os.listdir(path+data_name+'/'+typ),key=natural_sort_key):\n",
    "                    with Image.open(path+data_name+'/'+typ+'/'+img) as image:\n",
    "                        if (data_name=='train'):\n",
    "                            X_train.append(np.array(image))\n",
    "                            y_train.append(1 if typ=='malignant' else 0)\n",
    "                        else:\n",
    "                            X_test.append(np.array(image))\n",
    "                            y_test.append(1 if typ=='malignant' else 0)\n",
    "\n",
    "    X_train=np.array(X_train)\n",
    "    y_train=np.array(y_train)\n",
    "    X_test=np.array(X_test)\n",
    "    y_test=np.array(y_test)\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d9856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=getData(r'data/melanoma_cancer_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f83d8-cd6d-457c-a277-0dfcad7a75b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6307c3-3873-44fc-b6e6-05ebe2982a9c",
   "metadata": {},
   "source": [
    "***we'll preprocess images by converting to grayscale,scaling/resizing the default approach is to loop throught loaded X_train ,X_test but it's very resource intensive so we'll load images using batches of 100 images a time then save whole images into new folders ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfa929-8417-436f-afe3-f5811235d72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def scaleImage(img):\n",
    "    reshaped_array = img.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_array = scaler.fit_transform(reshaped_array)\n",
    "    scaled_image_array = scaled_array.reshape(img.shape)\n",
    "    return scaled_image_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09908dd4-b65d-419a-a04e-8b2e0d00cce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_images = len(X_train)\n",
    "processed_X_train = []\n",
    "for start in range(0, num_images, batch_size):\n",
    "    end = min(start + batch_size, num_images)\n",
    "    batch = X_train[start:end]\n",
    "    batch_gray = [cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY) for image_array in batch]\n",
    "    batch_processed = [cv2.resize(scaleImage(image), (200, 300)) for image in batch_gray]\n",
    "    processed_X_train.extend(batch_processed)\n",
    "\n",
    "processed_X_train = np.array(processed_X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb71fbe-ea2f-4be6-95ba-dac95672407f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_images = len(X_test)\n",
    "processed_images_X_test = []\n",
    "for start in range(0, num_images, batch_size):\n",
    "    end = min(start + batch_size, num_images)\n",
    "    batch = X_test[start:end]\n",
    "    batch_gray = [cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY) for image_array in batch]\n",
    "    batch_processed = [cv2.resize(scaleImage(image), (200, 300)) for image in batch_gray]\n",
    "    processed_images_X_test.extend(batch_processed)\n",
    "\n",
    "processed_X_test = np.array(processed_images_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945d372-d0fb-496a-b867-be9198bf6f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img=plt.imshow(processed_X_train[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60f631-b261-40da-bec8-04e84276645d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function here save using cmap ,unlike function below\n",
    "import matplotlib.pyplot as plt\n",
    "def saveToFile(compressed_img,name):#name with extension\n",
    "    plt.imsave(name, compressed_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d732691-6cd7-44a7-b270-04afd88fede5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path=\"data/melanoma_cancer_dataset/\"\n",
    "newDir=\"dataCreated/preproceed/\"\n",
    "#need shuffle?later in processing ,to make this code work\n",
    "\n",
    "os.makedirs(newDir+\"train/benign\", exist_ok=True)\n",
    "os.makedirs(newDir+\"train/malignant\", exist_ok=True)\n",
    "os.makedirs(newDir+\"test/benign\", exist_ok=True)\n",
    "os.makedirs(newDir+\"test/malignant\", exist_ok=True)\n",
    "for i,img in enumerate(processed_X_train):\n",
    "    if (y_train[i]==1):\n",
    "        saveToFile(processed_X_train[i],newDir+\"train/malignant/\"+str(i)+\".jpg\")#name of image changed ,not very important thing to aware\n",
    "    else:\n",
    "        saveToFile(processed_X_train[i],newDir+\"train/benign/\"+str(i)+\".jpg\")\n",
    "\n",
    "for i,img in enumerate(processed_X_test):\n",
    "    if (y_test[i]==1):\n",
    "        saveToFile(processed_X_test[i],newDir+\"test/malignant/\"+str(i)+\".jpg\")#name of image changed ,not very important thing to aware\n",
    "    else:\n",
    "        saveToFile(processed_X_test[i],newDir+\"test/benign/\"+str(i)+\".jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6f0f2-8f3a-49a8-9a6f-5e2e6a10899f",
   "metadata": {},
   "source": [
    "***important: to display grayed in plt must use cmap = 'gray'***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3e300-06da-45d4-998f-942a12c6e4dc",
   "metadata": {},
   "source": [
    "## reducing images size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04185f37-12f5-4292-a55a-fb0d677514ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### reducing using clustering algorithm\n",
    "(note preproceed with scaling,resizing have reduced some size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ff1c0-9d63-4ed7-850b-0a5959533430",
   "metadata": {},
   "source": [
    "***reload new preproceed data (and overwrite original data to help memory)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e420305-1875-4eef-b3a6-53f9095ba00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(processed_X_test)\n",
    "del(processed_X_train)\n",
    "X_train,y_train,X_test,y_test=getData(r'dataCreated/preproceed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38072cd-7a02-4545-9ef4-96aa48110406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img=plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f052194-ab89-4b40-8acc-fd1114614908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "def imageCompressKMean(Org_image,n_colors):#image if !png should be scaled by 255\n",
    "    img = Org_image.reshape((Org_image.shape[0] * Org_image.shape[1], 3))\n",
    "    kmeans = KMeans(n_clusters=n_colors, random_state=42,n_init=10)\n",
    "    kmeans.fit(img)\n",
    "    labels = kmeans.predict(img)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    quantized_image=centers[labels].reshape(Org_image.shape)\n",
    "    quantized_image = np.reshape(quantized_image, Org_image.shape) \n",
    "    return quantized_image\n",
    "def saveToFile(compressed_img,name):#name with extension\n",
    "    plt.imsave(name, compressed_img)\n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8afdde-7408-4d28-aac5-898d348e890d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test functions\n",
    "quantized_image=imageCompressKMean(X_train[70]/255,8)\n",
    "saveToFile(quantized_image,\"new_data.jpg\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.imshow(X_train[70])\n",
    "ax1.set_title(\"Original Image\")\n",
    "ax1.axis(\"off\")\n",
    "ax2.imshow(quantized_image)\n",
    "ax2.set_title(\"Quantized Image \")\n",
    "ax2.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a84e1-ebf9-4f3c-89b6-83d623b4a5e9",
   "metadata": {},
   "source": [
    "***trying to do last method on some images to see if it will actually reduce storage size so memory size when loading we'll try on any 500 images (say test/benign) which is 5MB \n",
    ",Note: can be done also using loaded images in memory but this to keep it simpler !\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a9598-bbe2-4b7b-bc6d-85d7fc341d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path=\"data/melanoma_cancer_dataset/test/benign/\"\n",
    "newDir=\"dataCreated/testKmean/\"\n",
    "os.makedirs(newDir, exist_ok=True)#to not raise error if exist\n",
    "\n",
    "for i,data_name in enumerate(os.listdir(path)):#enumerate just to say progress\n",
    "     with Image.open(path+data_name) as image:\n",
    "            quantized_image=imageCompressKMean(np.array(image),8)\n",
    "            saveToFile(quantized_image,newDir+str(data_name))\n",
    "            if (i%20==0):print(\"progress \"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24518b-f252-4970-a573-6d06a2e9fa36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(y_test[:500]==0)\n",
    "#from running last line we actually see that first 500 image in y_test are from benign folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e03486-1ea1-4b5c-9897-181a099acf37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#optimize above code\n",
    "newDir=\"dataCreated/testKmean/\"\n",
    "os.makedirs(newDir, exist_ok=True)#to not raise error if exist\n",
    "\n",
    "batch_size = 50\n",
    "num_images = len(X_test[:500])\n",
    "name_idx=0\n",
    "for start in range(0, num_images, batch_size):\n",
    "    end = min(start + batch_size, num_images)  \n",
    "    batch = X_test[start:end]\n",
    "    for image in batch:\n",
    "        quantized_image=imageCompressKMean(image/255,8)\n",
    "        name_idx=name_idx+1\n",
    "        saveToFile(quantized_image,newDir+str(name_idx)+'.jpg')\n",
    "    print(\"progress \"+str(start+batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ff15d-6d14-488d-a610-f7ca5096b26a",
   "metadata": {},
   "source": [
    "***from running last code and comparing size (using just windows) this method not good here ,this may because\n",
    "number of colors in images is not large so reducing the number won't compress images (small difference may be from rolling back from loading jpeg and resaving),we'll try using another \n",
    "method :PCA***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87cfb7-7684-4722-b962-57f6e1059878",
   "metadata": {
    "tags": []
   },
   "source": [
    "### reducing using dimensionality reduction (Feature reduction using PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907f0fb-e37d-49c0-9009-aa4d17abd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=getData(r'dataCreated/preproceed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f436f9-affd-4c8d-9ed5-17e4c5df32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_train=X_train\n",
    "processed_X_test=X_test\n",
    "X_train_flattened =processed_X_train.reshape(processed_X_train.shape[0], -1)\n",
    "X_test_flattened =processed_X_test.reshape(processed_X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a5efb-4aa3-477c-b47c-914125256c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "num_components = 100\n",
    "batch_size = 200  \n",
    "ipca = IncrementalPCA(n_components=num_components)\n",
    "\n",
    "for i in range(0, len(X_test_flattened), batch_size):\n",
    "    X_batch = X_test_flattened[i:i+batch_size]\n",
    "    ipca.partial_fit(X_batch)\n",
    "    if (i%20==0):\n",
    "        print(f\"proceed : {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b036c37-7633-4c1c-9906-2ad887469984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = np.vstack([ipca.transform(X_train_flattened[i:i+batch_size]) for i in range(0, len(X_train_flattened), batch_size)])\n",
    "X_test_pca = np.vstack([ipca.transform(X_test_flattened[i:i+batch_size]) for i in range(0, len(X_test_flattened), batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d702b-e028-4d8e-aaca-b7d553480351",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"PCAParts/\", exist_ok=True)\n",
    "\n",
    "for i in range(0, len(X_train_pca), batch_size):\n",
    "    batch = X_train_pca[i:i+batch_size]\n",
    "    reconstructed_batch = ipca.inverse_transform(batch)\n",
    "    np.save(f'PCAParts/reconstructed_batch_X_train_{i}', reconstructed_batch)\n",
    "\n",
    "for i in range(0, len(X_test_pca), batch_size):\n",
    "    batch = X_test_pca[i:i+batch_size]\n",
    "    reconstructed_batch = ipca.inverse_transform(batch)\n",
    "    np.save(f'PCAParts/reconstructed_batch_X_test_{i}', reconstructed_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa48c91-6ab6-4f17-b497-337c870d849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reconstructed = np.concatenate([np.load(f'PCAParts/reconstructed_batch_X_train_{i}.npy') for i in range(0, len(X_train_pca), batch_size)], axis=0)\n",
    "X_test_reconstructed = np.concatenate([np.load(f'PCAParts/reconstructed_batch_X_test_{i}.npy') for i in range(0, len(X_test_pca), batch_size)], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378fc5a-5d0f-4591-ae8c-97dcfca892f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e74397-f5c7-4ec1-96aa-8e90f3895c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f96ea2e0-90f4-4d53-b827-f7a277d5cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=getData(r'dataCreated/preproceed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "698669b9-27fd-4995-bd05-ef1e8c0541be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9605,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57bbfe67-fb0f-4d36-8bd7-1842ccb34682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "data = list(zip(X_train, y_train))\n",
    "random.shuffle(data)\n",
    "X_train, y_train = zip(*data)\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e8813d08-e329-4554-a9b6-7eecbe635a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "961/961 [==============================] - 383s 398ms/step - loss: 348.2306 - accuracy: 0.6426\n",
      "Epoch 2/10\n",
      "961/961 [==============================] - 379s 394ms/step - loss: 23.2454 - accuracy: 0.5854\n",
      "Epoch 3/10\n",
      "961/961 [==============================] - 362s 377ms/step - loss: 13.6099 - accuracy: 0.5466\n",
      "Epoch 4/10\n",
      "961/961 [==============================] - 365s 380ms/step - loss: 10.1577 - accuracy: 0.5462\n",
      "Epoch 5/10\n",
      "961/961 [==============================] - 377s 393ms/step - loss: 14.3646 - accuracy: 0.5198\n",
      "Epoch 6/10\n",
      "961/961 [==============================] - 370s 385ms/step - loss: 9.6522 - accuracy: 0.5209\n",
      "Epoch 7/10\n",
      "961/961 [==============================] - 430s 448ms/step - loss: 18.4479 - accuracy: 0.5197\n",
      "Epoch 8/10\n",
      "961/961 [==============================] - 368s 383ms/step - loss: 20.0511 - accuracy: 0.5201\n",
      "Epoch 9/10\n",
      "961/961 [==============================] - 369s 384ms/step - loss: 6.9527 - accuracy: 0.5193\n",
      "Epoch 10/10\n",
      "961/961 [==============================] - 372s 387ms/step - loss: 7.9417 - accuracy: 0.5200\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "lambada=.1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(Dense(1, activation='linear',kernel_regularizer=l2(lambada)))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs,workers=2)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0c582967-b24a-4cf6-aad6-917ddb1999a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('NNmodel.h5')#bad accuracy .5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abeaf2-98ca-4dbd-932d-b86910a9f8ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb158ac5-04c6-4701-9921-a29ad40301d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=getData(r'dataCreated/preproceed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8176eb-cab6-43de-9104-b607f79bafb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "data = list(zip(X_train, y_train))\n",
    "random.shuffle(data)\n",
    "X_train, y_train = zip(*data)\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f6e9f274-e8de-48bf-b87c-9c9a30265da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "961/961 [==============================] - 891s 926ms/step - loss: 19.3119 - accuracy: 0.6258\n",
      "Epoch 2/10\n",
      "961/961 [==============================] - 927s 964ms/step - loss: 4.9762 - accuracy: 0.6900\n",
      "Epoch 3/10\n",
      "961/961 [==============================] - 860s 895ms/step - loss: 2.3510 - accuracy: 0.7257\n",
      "Epoch 4/10\n",
      "961/961 [==============================] - 869s 904ms/step - loss: 1.2935 - accuracy: 0.7342\n",
      "Epoch 5/10\n",
      "961/961 [==============================] - 879s 914ms/step - loss: 0.8565 - accuracy: 0.7533\n",
      "Epoch 6/10\n",
      "961/961 [==============================] - 1057s 1s/step - loss: 0.6907 - accuracy: 0.7679\n",
      "Epoch 7/10\n",
      "961/961 [==============================] - 838s 872ms/step - loss: 0.6645 - accuracy: 0.7666\n",
      "Epoch 8/10\n",
      "961/961 [==============================] - 823s 856ms/step - loss: 0.6467 - accuracy: 0.7706\n",
      "Epoch 9/10\n",
      "961/961 [==============================] - 825s 858ms/step - loss: 0.6054 - accuracy: 0.7761\n",
      "Epoch 10/10\n",
      "961/961 [==============================] - 816s 849ms/step - loss: 0.5939 - accuracy: 0.7829\n",
      "Test accuracy: 0.8330000042915344\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "lambada=.1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:],kernel_regularizer=l2(lambada)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=l2(lambada)))\n",
    "model.add(Dense(1, activation='linear',kernel_regularizer=l2(lambada)))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, workers=2)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "235d2fea-0f60-4b83-b33b-04b644f083ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('CNN.h5') #accurracy 0.8330000042915344 ,loss 0.6077840328216553 (from 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cce438-d5ec-4fbe-accc-c58ced05b0e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get best model and deploy to h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5403e8-4cd5-485e-9e6f-c73eb38b8c98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdd04c-2f93-4135-9ae4-febfefdcd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=getData(r'dataCreated/preproceed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7089fd-ce05-44ba-8be2-5f2befd1af66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Example visualization: Histogram of the target variable (y_train)\n",
    "plt.hist(y_train, bins=10)\n",
    "plt.xlabel('Target Variable')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Target Variable (y_train)')\n",
    "plt.show()\n",
    "\n",
    "# Example visualization: Scatter plot of two features in X_train\n",
    "feature1 = X_train[:, 0]\n",
    "feature2 = X_train[:, 1]\n",
    "plt.scatter(feature1, feature2)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Scatter Plot of Feature 1 vs Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b56cd2-65da-4834-a5ba-b68c9aad7b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Visualize training data\n",
    "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique_classes, class_counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Data Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Visualize testing data\n",
    "unique_classes, class_counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique_classes, class_counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Testing Data Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a279d-6493-4c7f-8fc7-33e2225125c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = X_train[0]  # Assuming the first image in X_train\n",
    "plt.imshow(image)\n",
    "plt.title('Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Example visualization: Displaying a grid of multiple images\n",
    "num_rows = 2  # Number of rows in the grid\n",
    "num_cols = 3  # Number of columns in the grid\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 6))\n",
    "\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_cols):\n",
    "        index = i * num_cols + j\n",
    "        image = X_train[index]\n",
    "        axes[i, j].imshow(image)\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
